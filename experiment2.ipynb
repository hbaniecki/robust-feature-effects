{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from openxai.model import LoadModel\n",
    "from openxai.dataloader import return_loaders\n",
    "from captum.attr import Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_dependence(f, xs, X, s):\n",
    "    X_raw = X.copy()\n",
    "    X_raw[:, s] = xs\n",
    "    return f.predict_proba(X_raw)[:, 1].mean()\n",
    "\n",
    "def conditional_dependence(f, xs, X, s):\n",
    "    X_raw = X.copy()\n",
    "    X_s = X_raw[:, s]\n",
    "    epsilon = X_s.ptp() / 18\n",
    "    X_cond = X_raw[(X_s > xs - epsilon) & (X_s < xs + epsilon), :]\n",
    "    if X_cond.shape[0] == 0:\n",
    "        return partial_dependence(f, xs, X, s)\n",
    "    else:\n",
    "        X_cond[:, s] = xs\n",
    "        return f.predict_proba(X_cond)[:, 1].mean()\n",
    "\n",
    "def dale(f, xs, X, s):\n",
    "    explainer = Saliency(f)\n",
    "    X_raw = X.copy()\n",
    "    X_s = X_raw[:, s]\n",
    "    x_smin = X_s.min()\n",
    "    delta_x = X_s.ptp() / 18\n",
    "    k = 0\n",
    "    mu_k = 0\n",
    "    while x_smin + k * delta_x < xs:\n",
    "        S_k = (X_s > x_smin + k * delta_x) & (X_s < x_smin + (k+1) * delta_x)\n",
    "        if np.any(S_k):\n",
    "            X_k = X[S_k, :]\n",
    "            inputs = torch.as_tensor(X_k, dtype=torch.float)\n",
    "            inputs.requires_grad_()\n",
    "            mu_k += explainer.attribute(inputs, target=1, abs=False)[:, s].mean().item()\n",
    "        k += 1\n",
    "    return delta_x * mu_k        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_effects(model, X):\n",
    "    pd_dict = {}\n",
    "    cd_dict = {}\n",
    "    dale_dict = {}\n",
    "    for s in range(X.shape[1]):\n",
    "        X_s = X[:, s]\n",
    "        if len(np.unique(X_s)) < 3:\n",
    "            continue\n",
    "        pd_dict[s] = []\n",
    "        cd_dict[s] = []\n",
    "        dale_dict[s] = []\n",
    "        for xs in np.linspace(X_s.min(), X_s.max(), 18):\n",
    "            pd_dict[s] += [partial_dependence(model, xs, X, s)]\n",
    "            cd_dict[s] += [conditional_dependence(model, xs, X, s)]\n",
    "            dale_dict[s] += [dale(model, xs, X, s)]\n",
    "    return pd.DataFrame(pd_dict), pd.DataFrame(cd_dict), pd.DataFrame(dale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'dataset': [], 'sigma': [], 'seed': [], 'layer': [], 'dfe': [], 'performance': [], 'label': []})\n",
    "\n",
    "model_name = 'ann'\n",
    "for data_name in ['heloc', 'gaussian', 'pima', 'heart', 'adult', 'german']:\n",
    "    _, loader_test = return_loaders(data_name=data_name, download=True, batch_size=128)\n",
    "    X = loader_test.dataset.data\n",
    "    y = loader_test.dataset.targets.to_numpy()\n",
    "    model = LoadModel(data_name=data_name, ml_model=model_name, pretrained=True)\n",
    "    model.eval()\n",
    "    baseline = calculate_feature_effects(model, X)\n",
    "    for sigma in [0.1, 0.25, 0.5, 1]:\n",
    "        for seed in range(20):\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            for i in reversed(range(len(model.network))):\n",
    "                if isinstance(model.network[i], torch.nn.Linear):\n",
    "                    with torch.no_grad():\n",
    "                        # model.network[i] = torch.nn.Linear(model.network[i].weight.shape[1], model.network[i].weight.shape[0], bias=True)\n",
    "                        model.network[i].weight.add_(torch.randn(model.network[i].weight.size()) * sigma)\n",
    "                        model.network[i].bias.add_(torch.randn(model.network[i].bias.size()) * sigma)\n",
    "                    predictions = (model.predict_proba(X)[:, 1] >= 0.5).astype(int)\n",
    "                    pd_df, cd_df, dale_df = calculate_feature_effects(model, X)\n",
    "                    results = pd.concat([results, pd.DataFrame({\n",
    "                        'dataset': [data_name]*3,\n",
    "                        'sigma': [sigma]*3,\n",
    "                        'seed': [seed]*3,\n",
    "                        'layer': [int(1+i/2)]*3,\n",
    "                        'dfe': [np.abs(baseline[0]-pd_df).mean().mean(), np.abs(baseline[1]-cd_df).mean().mean(), np.abs(baseline[2]-dale_df).mean().mean()],\n",
    "                        'performance': [(y == predictions).mean()]*3,\n",
    "                        'label': ['marginal', 'conditional', 'accumulated']\n",
    "                    })])\n",
    "            model = LoadModel(data_name=data_name, ml_model=model_name, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results/model_perturbation_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"results/model_perturbation_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_title = {\"heloc\": \"HELOC\", \"gaussian\": \"Synthetic\", \"pima\": \"Pima\", \"heart\": \"Heart\", 'adult': \"Adult\", 'german': \"Credit\"}\n",
    "for data_name in ['heloc', 'gaussian', 'pima', 'heart', 'adult', 'german']:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    g = sns.lineplot(\n",
    "        data=results.loc[results.dataset == data_name,],\n",
    "        x=\"layer\", y=\"dfe\",\n",
    "        hue=\"label\", style=\"label\",\n",
    "        errorbar=\"se\",\n",
    "        linewidth=3,\n",
    "        palette=[\"#4285F4\", \"#DB4437\", \"#0F9D58\"] # \"#0F9D58\", \"#F4B400\", \"#4285F4\", \"#DB4437\"\n",
    "    )\n",
    "    g.set_title(data_to_title[data_name], fontsize=BIGGER_SIZE)\n",
    "    plt.legend(title=\"Feature effect\")\n",
    "    plt.xticks([1, 2, 3], ['Layer 1','Layer 2','Layer 3'])\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel(\"$\\sum_s \\; \\sum_{\\mathbf{x}_s} | g_s(\\mathbf{x}_s; f, p_{\\mathbf{X}}) - g_s(\\mathbf{x}_s ; f', p_{\\mathbf{X}}) |$\", fontsize=SMALL_SIZE)\n",
    "    plt.ylim([0, 0.4])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/exp2_{data_name}.pdf')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustfe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
